% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrds_update_pq.R
\name{wrds_update_pq}
\alias{wrds_update_pq}
\title{Export a WRDS table to Parquet, skipping if already up to date}
\usage{
wrds_update_pq(
  table_name,
  schema,
  data_dir = Sys.getenv("DATA_DIR", "."),
  out_file = NULL,
  force = FALSE,
  where = NULL,
  obs = NULL,
  keep = NULL,
  drop = NULL,
  alt_table_name = NULL,
  chunk_size = 100000L,
  col_types = NULL,
  tz = "UTC",
  archive = FALSE,
  archive_dir = "archive"
)
}
\arguments{
\item{table_name}{Name of the table in the WRDS PostgreSQL database.}

\item{schema}{Name of the database schema (e.g. \code{"crsp"}, \code{"comp"}).}

\item{data_dir}{Root directory of the local Parquet data repository. Defaults
to the \code{DATA_DIR} environment variable, or \code{"."} if unset. The
output file is written to \code{<data_dir>/<schema>/<table_name>.parquet}.}

\item{out_file}{Optional. Full path for the output Parquet file. Overrides
the path derived from \code{data_dir}, \code{schema}, and \code{table_name}.}

\item{force}{If \code{TRUE}, download proceeds regardless of the date
comparison result.}

\item{where}{Optional SQL \code{WHERE} clause (without the \code{WHERE}
keyword) to filter rows before export. For example,
\code{where = "date > '2020-01-01'"}.}

\item{obs}{Optional integer. Limits the number of rows imported using SQL
\code{LIMIT}. Useful for testing with large tables
(e.g. \code{obs = 1000}).}

\item{keep}{Optional character vector of regex patterns. Only columns whose
names match at least one pattern are retained. Applied after \code{drop}.}

\item{drop}{Optional character vector of regex patterns. Columns whose names
match at least one pattern are removed. Applied before \code{keep}.}

\item{alt_table_name}{Optional. Alternative basename for the output Parquet
file, used when the file should have a different name from \code{table_name}.}

\item{chunk_size}{Number of rows fetched and written per chunk. Default is
\code{100000}.}

\item{col_types}{Optional named list specifying column type overrides. Values
may be string type names (e.g. \code{"int32"}, \code{"float32"},
\code{"date"}) or Arrow \code{DataType} objects. Only columns that need to
differ from their inferred types need to be supplied. See
\code{\link{arrow_type}} for supported names. For example,
\code{col_types = list(permno = "int32", ret = "float32")}.}

\item{tz}{Time zone used to interpret \code{TIMESTAMP WITHOUT TIME ZONE}
columns. Such columns are cast to \code{TIMESTAMPTZ} in the SQL query using
\code{AT TIME ZONE}, so they are written as UTC-normalised timestamps in the
Parquet file. Defaults to \code{"UTC"}. Set to \code{NULL} to leave naive
timestamps as-is.}

\item{archive}{If \code{TRUE}, the existing local Parquet file (if any) is
moved to the archive subdirectory before being replaced. The archived
filename is \code{<table>_<YYYYMMDDTHHMMSSz>.parquet}, where the timestamp
suffix is derived from the WRDS table comment.}

\item{archive_dir}{Name of the archive subdirectory relative to the schema
directory. Defaults to \code{"archive"}.}
}
\value{
Invisibly returns the path to the Parquet file if written, or
\code{NULL} if the update was skipped.
}
\description{
Exports a table from the WRDS PostgreSQL database to a Parquet file. Before
downloading, the WRDS table comment is compared against the \code{last_modified}
metadata embedded in any existing local Parquet file. The download is skipped
if the local file is already up to date, making this function safe to call
repeatedly as part of a scheduled data refresh.
}
\examples{
\dontrun{
wrds_update_pq("dsi", "crsp")
wrds_update_pq("feed21_bankruptcy_notification", "audit")

# Force re-download even if local file is current
wrds_update_pq("dsi", "crsp", force = TRUE)

# Limit columns and rows (useful for testing)
wrds_update_pq("dsf", "crsp", obs = 1000, keep = c("permno", "date", "ret"))
}

}
\seealso{
\code{\link{pq_last_modified}}, \code{\link{pq_archive}}, \code{\link{pq_restore}}
}
